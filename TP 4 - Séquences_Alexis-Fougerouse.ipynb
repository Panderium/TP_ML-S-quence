{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4 - SÃ©quences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1122304/1115394 [==============================] - 1s 1us/step\n",
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])\n",
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen' ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size \n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences, \n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead, \n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  tf.Tensor(\n",
      "[[52 53 58 46 47 52 45  1 43 50 57 43  0 14 59 58  1 58 46 39 58  1 21  1\n",
      "  61 39 57  1 39  1 48 53 59 56 52 43 63 51 39 52  1 58 53  1 45 56 47 43\n",
      "  44 12  0  0 22 27 20 26  1 27 18  1 19 13 33 26 32 10  0 13 50 50  1 54\n",
      "  50 39 41 43 57  1 58 46 39 58  1 58 46 43  1 43 63 43  1 53 44  1 46 43\n",
      "  39 60 43 52]\n",
      " [60 43  1 52 53  1 57 58 39 44 44  6  1 52 53  1 57 58 39 63  8  0 27  1\n",
      "  15 50 47 44 44 53 56 42  6  1 40 53 47 57 58 43 56 53 59 57  1 15 50 47\n",
      "  44 44 53 56 42  2  1 58 46 53 59  1 46 39 57 58  1 57 50 39 47 52  0 32\n",
      "  46 43  1 44 50 53 61 43 56  1 53 44  1 17 59 56 53 54 43  1 44 53 56  1\n",
      "  46 47 57  1]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[53 58 46 47 52 45  1 43 50 57 43  0 14 59 58  1 58 46 39 58  1 21  1 61\n",
      "  39 57  1 39  1 48 53 59 56 52 43 63 51 39 52  1 58 53  1 45 56 47 43 44\n",
      "  12  0  0 22 27 20 26  1 27 18  1 19 13 33 26 32 10  0 13 50 50  1 54 50\n",
      "  39 41 43 57  1 58 46 39 58  1 58 46 43  1 43 63 43  1 53 44  1 46 43 39\n",
      "  60 43 52  1]\n",
      " [43  1 52 53  1 57 58 39 44 44  6  1 52 53  1 57 58 39 63  8  0 27  1 15\n",
      "  50 47 44 44 53 56 42  6  1 40 53 47 57 58 43 56 53 59 57  1 15 50 47 44\n",
      "  44 53 56 42  2  1 58 46 53 59  1 46 39 57 58  1 57 50 39 47 52  0 32 46\n",
      "  43  1 44 50 53 61 43 56  1 53 44  1 17 59 56 53 54 43  1 44 53 56  1 46\n",
      "  47 57  1 41]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[50 39 52 41 43 11  1 39 52 42  1 19 53 42  1 42 43 44 43 52 42  1 58 46\n",
      "  43  1 56 47 45 46 58  2  0  0 20 17 26 30 37  1 14 27 24 21 26 19 14 30\n",
      "  27 23 17 10  0 31 58 56 53 52 45  1 39 57  1 39  1 58 53 61 43 56  1 47\n",
      "  52  1 46 53 54 43  6  1 21  1 41 56 63  1 39 51 43 52  8  0  0 24 53 56\n",
      "  42  1 25 39]\n",
      " [46 53 59 50 42  1 46 39 60 43  1 58 53 57 57  5 42  1 51 43  1 53 52  1\n",
      "  58 46 43 47 56  1 54 47 49 43 57  0 14 43 44 53 56 43  1 21  1 61 53 59\n",
      "  50 42  1 46 39 60 43  1 45 56 39 52 58 43 42  1 58 53  1 58 46 39 58  1\n",
      "  39 41 58  8  0 14 59 58  1 58 46 53 59  1 54 56 43 44 43 56 56  5 57 58\n",
      "   1 58 46 63]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[39 52 41 43 11  1 39 52 42  1 19 53 42  1 42 43 44 43 52 42  1 58 46 43\n",
      "   1 56 47 45 46 58  2  0  0 20 17 26 30 37  1 14 27 24 21 26 19 14 30 27\n",
      "  23 17 10  0 31 58 56 53 52 45  1 39 57  1 39  1 58 53 61 43 56  1 47 52\n",
      "   1 46 53 54 43  6  1 21  1 41 56 63  1 39 51 43 52  8  0  0 24 53 56 42\n",
      "   1 25 39 56]\n",
      " [53 59 50 42  1 46 39 60 43  1 58 53 57 57  5 42  1 51 43  1 53 52  1 58\n",
      "  46 43 47 56  1 54 47 49 43 57  0 14 43 44 53 56 43  1 21  1 61 53 59 50\n",
      "  42  1 46 39 60 43  1 45 56 39 52 58 43 42  1 58 53  1 58 46 39 58  1 39\n",
      "  41 58  8  0 14 59 58  1 58 46 53 59  1 54 56 43 44 43 56 56  5 57 58  1\n",
      "  58 46 63  1]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[46 43 52  1 51 63  1 44 39 41 43  1 47 57  1 44 39 47 56  6  1 63 53 59\n",
      "   1 57 46 39 50 50  1 54 43 56 41 43 47 60 43  0 35 46 43 58 46 43 56  1\n",
      "  21  1 40 50 59 57 46  1 53 56  1 52 53 10  1 46 53 61 40 43 47 58  6  1\n",
      "  21  1 58 46 39 52 49  1 63 53 59  8  0 21  1 51 43 39 52  1 58 53  1 57\n",
      "  58 56 47 42]\n",
      " [52 53 59 56 57  0 35 46 47 41 46  1 61 43  1 42 43 60 47 57 43  1 46 47\n",
      "  51  8  0  0 15 27 25 21 26 21 33 31 10  0 27 59 56  1 57 54 53 47 50 57\n",
      "   1 46 43  1 49 47 41 49  5 42  1 39 58  6  0 13 52 42  1 50 53 53 49  5\n",
      "  42  1 59 54 53 52  1 58 46 47 52 45 57  1 54 56 43 41 47 53 59 57  1 39\n",
      "  57  1 58 46]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[43 52  1 51 63  1 44 39 41 43  1 47 57  1 44 39 47 56  6  1 63 53 59  1\n",
      "  57 46 39 50 50  1 54 43 56 41 43 47 60 43  0 35 46 43 58 46 43 56  1 21\n",
      "   1 40 50 59 57 46  1 53 56  1 52 53 10  1 46 53 61 40 43 47 58  6  1 21\n",
      "   1 58 46 39 52 49  1 63 53 59  8  0 21  1 51 43 39 52  1 58 53  1 57 58\n",
      "  56 47 42 43]\n",
      " [53 59 56 57  0 35 46 47 41 46  1 61 43  1 42 43 60 47 57 43  1 46 47 51\n",
      "   8  0  0 15 27 25 21 26 21 33 31 10  0 27 59 56  1 57 54 53 47 50 57  1\n",
      "  46 43  1 49 47 41 49  5 42  1 39 58  6  0 13 52 42  1 50 53 53 49  5 42\n",
      "   1 59 54 53 52  1 58 46 47 52 45 57  1 54 56 43 41 47 53 59 57  1 39 57\n",
      "   1 58 46 43]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[41 50 59 42 43 42  1 58 46 39 58  1 46 43  1 57 46 39 50 50  1 40 43  1\n",
      "  54 56 53 58 43 41 58 53 56 12  0  0 29 33 17 17 26  1 17 24 21 38 13 14\n",
      "  17 32 20 10  0 21 58  1 47 57  1 42 43 58 43 56 51 47 52 43 42  6  1 52\n",
      "  53 58  1 41 53 52 41 50 59 42 43 42  1 63 43 58 10  0 14 59 58  1 57 53\n",
      "   1 47 58  1]\n",
      " [ 1 39 52 42  0 58 53 39 42 57  1 41 39 56 40 53 52 39 42 53 43 42  8  0\n",
      "   0 25 27 28 31 13 10  0 21 57  1 47 58  1 58 56 59 43  6  1 58 46 47 52\n",
      "  49  1 63 53 59 12  0  0 13 33 32 27 24 37 15 33 31 10  0 34 43 56 63  1\n",
      "  58 56 59 43  6  1 39 52 42  1 40 59 58  1 39  1 51 53 52 58 46  1 53 50\n",
      "  42  8  0  0]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[50 59 42 43 42  1 58 46 39 58  1 46 43  1 57 46 39 50 50  1 40 43  1 54\n",
      "  56 53 58 43 41 58 53 56 12  0  0 29 33 17 17 26  1 17 24 21 38 13 14 17\n",
      "  32 20 10  0 21 58  1 47 57  1 42 43 58 43 56 51 47 52 43 42  6  1 52 53\n",
      "  58  1 41 53 52 41 50 59 42 43 42  1 63 43 58 10  0 14 59 58  1 57 53  1\n",
      "  47 58  1 51]\n",
      " [39 52 42  0 58 53 39 42 57  1 41 39 56 40 53 52 39 42 53 43 42  8  0  0\n",
      "  25 27 28 31 13 10  0 21 57  1 47 58  1 58 56 59 43  6  1 58 46 47 52 49\n",
      "   1 63 53 59 12  0  0 13 33 32 27 24 37 15 33 31 10  0 34 43 56 63  1 58\n",
      "  56 59 43  6  1 39 52 42  1 40 59 58  1 39  1 51 53 52 58 46  1 53 50 42\n",
      "   8  0  0 16]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[20 10  0 32 46 39 58  1 39 58  1 46 43 56  1 46 39 52 42 57  1 61 46 47\n",
      "  41 46  1 58 46 43  1 49 47 52 45  5 57  1 23 47 52 45  1 44 53 56 40 47\n",
      "  42 57  8  0  0 23 21 26 19  1 30 21 15 20 13 30 16  1 21 21 21 10  0 31\n",
      "  39 63  6  1 57 46 43  1 57 46 39 50 50  1 40 43  1 39  1 46 47 45 46  1\n",
      "  39 52 42  1]\n",
      " [53 50 47 52 45 40 56 53 49 43  1 57 39 63 57  1 39 63  8  0  0 26 27 30\n",
      "  32 20 33 25 14 17 30 24 13 26 16 10  0 25 63  1 50 53 56 42  6  1 47 52\n",
      "   1 58 46 43  1 40 39 57 43  1 41 53 59 56 58  1 46 43  1 42 53 58 46  1\n",
      "  39 58 58 43 52 42  0 32 53  1 57 54 43 39 49  1 61 47 58 46  1 63 53 59\n",
      "  11  1 51 39]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[10  0 32 46 39 58  1 39 58  1 46 43 56  1 46 39 52 42 57  1 61 46 47 41\n",
      "  46  1 58 46 43  1 49 47 52 45  5 57  1 23 47 52 45  1 44 53 56 40 47 42\n",
      "  57  8  0  0 23 21 26 19  1 30 21 15 20 13 30 16  1 21 21 21 10  0 31 39\n",
      "  63  6  1 57 46 43  1 57 46 39 50 50  1 40 43  1 39  1 46 47 45 46  1 39\n",
      "  52 42  1 51]\n",
      " [50 47 52 45 40 56 53 49 43  1 57 39 63 57  1 39 63  8  0  0 26 27 30 32\n",
      "  20 33 25 14 17 30 24 13 26 16 10  0 25 63  1 50 53 56 42  6  1 47 52  1\n",
      "  58 46 43  1 40 39 57 43  1 41 53 59 56 58  1 46 43  1 42 53 58 46  1 39\n",
      "  58 58 43 52 42  0 32 53  1 57 54 43 39 49  1 61 47 58 46  1 63 53 59 11\n",
      "   1 51 39 63]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[ 1 58 46 39 58  1 63 53 59  1 51 39 63  7  7  0 18 53 56  1 21  1 42 53\n",
      "   1 44 43 39 56  1 43 63 43 57  1 53 60 43 56  7  7 58 53  1 57 46 47 54\n",
      "  40 53 39 56 42  0 19 43 58  1 59 52 42 43 57 41 56 47 43 42  8  0  0 28\n",
      "  17 30 16 21 32 13 10  0 21  1 57 43 43  1 58 46 43  1 54 50 39 63  1 57\n",
      "  53  1 50 47]\n",
      " [ 5 58 10  1 52 53 58  1 39  1 51 53 52 58 46  0  5 18 53 56 43  1 63 53\n",
      "  59 56  1 55 59 43 43 52  1 42 47 43 42  6  1 57 46 43  1 61 39 57  1 51\n",
      "  53 56 43  1 61 53 56 58 46  1 57 59 41 46  1 45 39 64 43 57  0 32 46 39\n",
      "  52  1 61 46 39 58  1 63 53 59  1 50 53 53 49  1 53 52  1 52 53 61  8  0\n",
      "   0 24 17 27]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[58 46 39 58  1 63 53 59  1 51 39 63  7  7  0 18 53 56  1 21  1 42 53  1\n",
      "  44 43 39 56  1 43 63 43 57  1 53 60 43 56  7  7 58 53  1 57 46 47 54 40\n",
      "  53 39 56 42  0 19 43 58  1 59 52 42 43 57 41 56 47 43 42  8  0  0 28 17\n",
      "  30 16 21 32 13 10  0 21  1 57 43 43  1 58 46 43  1 54 50 39 63  1 57 53\n",
      "   1 50 47 43]\n",
      " [58 10  1 52 53 58  1 39  1 51 53 52 58 46  0  5 18 53 56 43  1 63 53 59\n",
      "  56  1 55 59 43 43 52  1 42 47 43 42  6  1 57 46 43  1 61 39 57  1 51 53\n",
      "  56 43  1 61 53 56 58 46  1 57 59 41 46  1 45 39 64 43 57  0 32 46 39 52\n",
      "   1 61 46 39 58  1 63 53 59  1 50 53 53 49  1 53 52  1 52 53 61  8  0  0\n",
      "  24 17 27 26]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[ 1 47 52 61 39 56 42  1 57 53 59 50  0 28 43 56 57 59 39 42 43 57  1 51\n",
      "  43  1 47 58  1 47 57  1 53 58 46 43 56 61 47 57 43 10  1 46 53 61 43  5\n",
      "  43 56  1 47 58  1 40 43  6  0 21  1 41 39 52 52 53 58  1 40 59 58  1 40\n",
      "  43  1 57 39 42 11  1 57 53  1 46 43 39 60 63  1 57 39 42  0 13 57  6  1\n",
      "  58 46 53 59]\n",
      " [39 58  1 63 53 59  1 45 39 60 43  1 47 52  1 41 46 39 56 45 43  6  0 21\n",
      "  57  1 52 53 61  1 42 47 57 46 53 52 53 59 56 43 42  1 40 63  1 58 46 47\n",
      "  57  1 52 43 61  1 51 39 56 56 47 39 45 43  8  0  0 23 21 26 19  1 17 16\n",
      "  35 13 30 16  1 21 34 10  0 35 46 39 58  1 47 44  1 40 53 58 46  1 24 43\n",
      "  61 47 57  1]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[47 52 61 39 56 42  1 57 53 59 50  0 28 43 56 57 59 39 42 43 57  1 51 43\n",
      "   1 47 58  1 47 57  1 53 58 46 43 56 61 47 57 43 10  1 46 53 61 43  5 43\n",
      "  56  1 47 58  1 40 43  6  0 21  1 41 39 52 52 53 58  1 40 59 58  1 40 43\n",
      "   1 57 39 42 11  1 57 53  1 46 43 39 60 63  1 57 39 42  0 13 57  6  1 58\n",
      "  46 53 59 45]\n",
      " [58  1 63 53 59  1 45 39 60 43  1 47 52  1 41 46 39 56 45 43  6  0 21 57\n",
      "   1 52 53 61  1 42 47 57 46 53 52 53 59 56 43 42  1 40 63  1 58 46 47 57\n",
      "   1 52 43 61  1 51 39 56 56 47 39 45 43  8  0  0 23 21 26 19  1 17 16 35\n",
      "  13 30 16  1 21 34 10  0 35 46 39 58  1 47 44  1 40 53 58 46  1 24 43 61\n",
      "  47 57  1 39]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[47 53 52 57  6  1 39 57  1 21  1 46 43 39 56  6  1 51 53 56 43  1 57 58\n",
      "  56 53 52 45  0 32 46 39 52  1 39 56 43  1 59 54 53 52  1 63 53 59  1 63\n",
      "  43 58  8  0  0 15 27 30 21 27 24 13 26 33 31 10  0 32 46 43  1 61 53 56\n",
      "  42  1 47 57  1  5 51 47 50 42 50 63  8  5  1 28 56 39 63  1 63 53 59  6\n",
      "   1 50 43 58]\n",
      " [44 56 53 51  1 58 46 43  1 60 47 52 43 63 39 56 42  1 58 53  1 58 46 43\n",
      "   1 45 39 56 42 43 52  1 50 43 39 42 57 11  0 32 46 43 56 43  1 46 39 60\n",
      "  43  1 21  1 51 39 42 43  1 51 63  1 54 56 53 51 47 57 43  0 33 54 53 52\n",
      "   1 58 46 43  1 46 43 39 60 63  1 51 47 42 42 50 43  1 53 44  1 58 46 43\n",
      "   1 52 47 45]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[53 52 57  6  1 39 57  1 21  1 46 43 39 56  6  1 51 53 56 43  1 57 58 56\n",
      "  53 52 45  0 32 46 39 52  1 39 56 43  1 59 54 53 52  1 63 53 59  1 63 43\n",
      "  58  8  0  0 15 27 30 21 27 24 13 26 33 31 10  0 32 46 43  1 61 53 56 42\n",
      "   1 47 57  1  5 51 47 50 42 50 63  8  5  1 28 56 39 63  1 63 53 59  6  1\n",
      "  50 43 58  1]\n",
      " [56 53 51  1 58 46 43  1 60 47 52 43 63 39 56 42  1 58 53  1 58 46 43  1\n",
      "  45 39 56 42 43 52  1 50 43 39 42 57 11  0 32 46 43 56 43  1 46 39 60 43\n",
      "   1 21  1 51 39 42 43  1 51 63  1 54 56 53 51 47 57 43  0 33 54 53 52  1\n",
      "  58 46 43  1 46 43 39 60 63  1 51 47 42 42 50 43  1 53 44  1 58 46 43  1\n",
      "  52 47 45 46]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[ 1 42 56 39 61  1 47 52  1 51 39 52 63  1 39  1 58 43 39 56  0 13 52 42\n",
      "   1 57 58 53 54  1 58 46 43  1 56 47 57 47 52 45  1 53 44  1 40 50 53 53\n",
      "  42  7 57 59 41 49 47 52 45  1 57 47 45 46 57  6  0 24 43 57 58  1 61 47\n",
      "  58 46  1 51 63  1 57 47 45 46 57  1 53 56  1 58 43 39 56 57  1 21  1 40\n",
      "  50 39 57 58]\n",
      " [57 46 56 47 52 49  1 44 56 53 51  1 46 47 51  8  0  0 30 21 15 20 25 27\n",
      "  26 16 10  0 13 50 50  1 44 53 56  1 53 59 56  1 60 39 52 58 39 45 43  8\n",
      "   1 32 46 43 52  6  1 47 52  1 19 53 42  5 57  1 52 39 51 43  6  1 51 39\n",
      "  56 41 46 10  0 32 56 59 43  1 46 53 54 43  1 47 57  1 57 61 47 44 58  6\n",
      "   1 39 52 42]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[42 56 39 61  1 47 52  1 51 39 52 63  1 39  1 58 43 39 56  0 13 52 42  1\n",
      "  57 58 53 54  1 58 46 43  1 56 47 57 47 52 45  1 53 44  1 40 50 53 53 42\n",
      "   7 57 59 41 49 47 52 45  1 57 47 45 46 57  6  0 24 43 57 58  1 61 47 58\n",
      "  46  1 51 63  1 57 47 45 46 57  1 53 56  1 58 43 39 56 57  1 21  1 40 50\n",
      "  39 57 58  1]\n",
      " [46 56 47 52 49  1 44 56 53 51  1 46 47 51  8  0  0 30 21 15 20 25 27 26\n",
      "  16 10  0 13 50 50  1 44 53 56  1 53 59 56  1 60 39 52 58 39 45 43  8  1\n",
      "  32 46 43 52  6  1 47 52  1 19 53 42  5 57  1 52 39 51 43  6  1 51 39 56\n",
      "  41 46 10  0 32 56 59 43  1 46 53 54 43  1 47 57  1 57 61 47 44 58  6  1\n",
      "  39 52 42  1]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[21 15 23 10  0 13 63  6  1 40 59 58  1 46 43  5 57  1 42 43 39 42 10  1\n",
      "  53 44 44  1 61 47 58 46  1 58 46 43  1 58 56 39 47 58 53 56  5 57  1 46\n",
      "  43 39 42  6  0 13 52 42  1 56 43 39 56  1 47 58  1 47 52  1 58 46 43  1\n",
      "  54 50 39 41 43  1 63 53 59 56  1 44 39 58 46 43 56  5 57  1 57 58 39 52\n",
      "  42 57  8  0]\n",
      " [50 53 56 42  1 53 44  1 17 50 63  2  0  0 14 21 31 20 27 28  1 27 18  1\n",
      "  17 24 37 10  0 25 63  1 50 53 56 42 12  0  0 19 24 27 33 15 17 31 32 17\n",
      "  30 10  0 35 46 43 52  1 21  1 61 39 57  1 50 39 57 58  1 47 52  1 20 53\n",
      "  50 40 53 56 52  6  0 21  1 57 39 61  1 45 53 53 42  1 57 58 56 39 61 40\n",
      "  43 56 56 47]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[15 23 10  0 13 63  6  1 40 59 58  1 46 43  5 57  1 42 43 39 42 10  1 53\n",
      "  44 44  1 61 47 58 46  1 58 46 43  1 58 56 39 47 58 53 56  5 57  1 46 43\n",
      "  39 42  6  0 13 52 42  1 56 43 39 56  1 47 58  1 47 52  1 58 46 43  1 54\n",
      "  50 39 41 43  1 63 53 59 56  1 44 39 58 46 43 56  5 57  1 57 58 39 52 42\n",
      "  57  8  0 13]\n",
      " [53 56 42  1 53 44  1 17 50 63  2  0  0 14 21 31 20 27 28  1 27 18  1 17\n",
      "  24 37 10  0 25 63  1 50 53 56 42 12  0  0 19 24 27 33 15 17 31 32 17 30\n",
      "  10  0 35 46 43 52  1 21  1 61 39 57  1 50 39 57 58  1 47 52  1 20 53 50\n",
      "  40 53 56 52  6  0 21  1 57 39 61  1 45 53 53 42  1 57 58 56 39 61 40 43\n",
      "  56 56 47 43]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[ 1 61 39 57  1 41 39 57 58 47 52 45  1 59 54  1 53 44  1 43 63 43 57  6\n",
      "   0 46 53 50 42 47 52 45  1 59 54  1 53 44  1 46 39 52 42 57  6  1 61 47\n",
      "  58 46  1 41 53 59 52 58 43 52 39 52 41 43 57  1 53 44  1 57 59 41 46  0\n",
      "  42 47 57 58 56 39 41 58 47 53 52  1 58 46 39 58  1 58 46 43 63  1 61 43\n",
      "  56 43  1 58]\n",
      " [46 47 57  1 59 52 42 43 56 57 58 39 52 42 47 52 45  1 47 57  1 40 43 56\n",
      "  43 44 58  8  0 31 54 43 39 49  6  1 15 50 47 44 44 53 56 42  6  1 42 53\n",
      "  57 58  1 58 46 53 59  1 49 52 53 61  1 61 46 53  1 57 54 43 39 49 57  1\n",
      "  58 53  1 58 46 43 43 12  0 16 39 56 49  1 41 50 53 59 42 63  1 42 43 39\n",
      "  58 46  1 53]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[61 39 57  1 41 39 57 58 47 52 45  1 59 54  1 53 44  1 43 63 43 57  6  0\n",
      "  46 53 50 42 47 52 45  1 59 54  1 53 44  1 46 39 52 42 57  6  1 61 47 58\n",
      "  46  1 41 53 59 52 58 43 52 39 52 41 43 57  1 53 44  1 57 59 41 46  0 42\n",
      "  47 57 58 56 39 41 58 47 53 52  1 58 46 39 58  1 58 46 43 63  1 61 43 56\n",
      "  43  1 58 53]\n",
      " [47 57  1 59 52 42 43 56 57 58 39 52 42 47 52 45  1 47 57  1 40 43 56 43\n",
      "  44 58  8  0 31 54 43 39 49  6  1 15 50 47 44 44 53 56 42  6  1 42 53 57\n",
      "  58  1 58 46 53 59  1 49 52 53 61  1 61 46 53  1 57 54 43 39 49 57  1 58\n",
      "  53  1 58 46 43 43 12  0 16 39 56 49  1 41 50 53 59 42 63  1 42 43 39 58\n",
      "  46  1 53  5]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[43 56 43  1 47 58  1 42 47 42  1 51 39 56 49  6  1 47 58  1 58 53 53 49\n",
      "  11  1 44 56 53 51  1 44 39 41 43  1 58 53  1 44 53 53 58  0 20 43  1 61\n",
      "  39 57  1 39  1 58 46 47 52 45  1 53 44  1 40 50 53 53 42  6  1 61 46 53\n",
      "  57 43  1 43 60 43 56 63  1 51 53 58 47 53 52  0 35 39 57  1 58 47 51 43\n",
      "  42  1 61 47]\n",
      " [59 41 58  1 52 53 61  2  0 26 53 61  6  1 32 63 40 39 50 58  6  1 58 39\n",
      "  49 43  1 58 46 43  1 60 47 50 50 39 47 52  1 40 39 41 49  1 39 45 39 47\n",
      "  52  6  0 32 46 39 58  1 50 39 58 43  1 58 46 53 59  1 45 39 60 43 57 58\n",
      "   1 51 43 11  1 44 53 56  1 25 43 56 41 59 58 47 53  5 57  1 57 53 59 50\n",
      "   0 21 57  1]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[56 43  1 47 58  1 42 47 42  1 51 39 56 49  6  1 47 58  1 58 53 53 49 11\n",
      "   1 44 56 53 51  1 44 39 41 43  1 58 53  1 44 53 53 58  0 20 43  1 61 39\n",
      "  57  1 39  1 58 46 47 52 45  1 53 44  1 40 50 53 53 42  6  1 61 46 53 57\n",
      "  43  1 43 60 43 56 63  1 51 53 58 47 53 52  0 35 39 57  1 58 47 51 43 42\n",
      "   1 61 47 58]\n",
      " [41 58  1 52 53 61  2  0 26 53 61  6  1 32 63 40 39 50 58  6  1 58 39 49\n",
      "  43  1 58 46 43  1 60 47 50 50 39 47 52  1 40 39 41 49  1 39 45 39 47 52\n",
      "   6  0 32 46 39 58  1 50 39 58 43  1 58 46 53 59  1 45 39 60 43 57 58  1\n",
      "  51 43 11  1 44 53 56  1 25 43 56 41 59 58 47 53  5 57  1 57 53 59 50  0\n",
      "  21 57  1 40]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[ 1 61 39 56  6  1 40 59 58  1 39 58  1 46 47 57  1 52 59 56 57 43  5 57\n",
      "   1 58 43 39 56 57  0 20 43  1 61 46 47 52 43 42  1 39 52 42  1 56 53 39\n",
      "  56  5 42  1 39 61 39 63  1 63 53 59 56  1 60 47 41 58 53 56 63  6  0 32\n",
      "  46 39 58  1 54 39 45 43 57  1 40 50 59 57 46  5 42  1 39 58  1 46 47 51\n",
      "   1 39 52 42]\n",
      " [43  8  0 31 47 56 56 39 46  6  1 61 46 43 56 43  1 46 39 60 43  1 63 53\n",
      "  59  1 40 43 43 52 12  0  0 14 21 27 26 16 17 24 24 27 10  0 35 46 43 56\n",
      "  43  1 46 39 60 43  1 21  1 40 43 43 52  2  1 26 39 63  6  1 46 53 61  1\n",
      "  52 53 61  2  1 61 46 43 56 43  1 39 56 43  1 63 53 59 12  0 25 39 57 58\n",
      "  43 56  6  1]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[61 39 56  6  1 40 59 58  1 39 58  1 46 47 57  1 52 59 56 57 43  5 57  1\n",
      "  58 43 39 56 57  0 20 43  1 61 46 47 52 43 42  1 39 52 42  1 56 53 39 56\n",
      "   5 42  1 39 61 39 63  1 63 53 59 56  1 60 47 41 58 53 56 63  6  0 32 46\n",
      "  39 58  1 54 39 45 43 57  1 40 50 59 57 46  5 42  1 39 58  1 46 47 51  1\n",
      "  39 52 42  1]\n",
      " [ 8  0 31 47 56 56 39 46  6  1 61 46 43 56 43  1 46 39 60 43  1 63 53 59\n",
      "   1 40 43 43 52 12  0  0 14 21 27 26 16 17 24 24 27 10  0 35 46 43 56 43\n",
      "   1 46 39 60 43  1 21  1 40 43 43 52  2  1 26 39 63  6  1 46 53 61  1 52\n",
      "  53 61  2  1 61 46 43 56 43  1 39 56 43  1 63 53 59 12  0 25 39 57 58 43\n",
      "  56  6  1 46]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[43 56  8  0  0 19 30 33 25 21 27 10  0 35 46 63  6  1 57 46 43  1 41 53\n",
      "  51 43 57  1 58 53  1 40 53 56 56 53 61  1 52 53 58 46 47 52 45  1 53 44\n",
      "   1 58 46 43 51  8  0  0 26 13 32 20 13 26 21 17 24 10  0 35 43 50 41 53\n",
      "  51 43  1 46 53 51 43  6  1 19 56 59 51 47 53  2  0  0 28 20 21 24 21 28\n",
      "  10  0 20 53]\n",
      " [47 44 43  1 53 44  1 35 47 52 41 53 58  6  1 47 44  0 57 46 43  1 49 52\n",
      "  53 61  1 51 43  1 52 53 58 10  1 47 44  1 57 46 43  1 57 39 63  1 21  1\n",
      "  39 51  1 52 53 58  1 44 53 59 56 58 43 43 52  1 54 43 52 41 43  0 53 52\n",
      "   1 58 46 43  1 57 41 53 56 43  1 44 53 56  1 57 46 43 43 56  1 39 50 43\n",
      "   6  1 57 41]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[56  8  0  0 19 30 33 25 21 27 10  0 35 46 63  6  1 57 46 43  1 41 53 51\n",
      "  43 57  1 58 53  1 40 53 56 56 53 61  1 52 53 58 46 47 52 45  1 53 44  1\n",
      "  58 46 43 51  8  0  0 26 13 32 20 13 26 21 17 24 10  0 35 43 50 41 53 51\n",
      "  43  1 46 53 51 43  6  1 19 56 59 51 47 53  2  0  0 28 20 21 24 21 28 10\n",
      "   0 20 53 61]\n",
      " [44 43  1 53 44  1 35 47 52 41 53 58  6  1 47 44  0 57 46 43  1 49 52 53\n",
      "  61  1 51 43  1 52 53 58 10  1 47 44  1 57 46 43  1 57 39 63  1 21  1 39\n",
      "  51  1 52 53 58  1 44 53 59 56 58 43 43 52  1 54 43 52 41 43  0 53 52  1\n",
      "  58 46 43  1 57 41 53 56 43  1 44 53 56  1 57 46 43 43 56  1 39 50 43  6\n",
      "   1 57 41 53]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[43 63  6  0 32 46 39 58  1 21  1 51 39 63  1 50 47 60 43  1 58 53  1 57\n",
      "  39 63  6  1 32 46 43  1 42 53 45  1 47 57  1 42 43 39 42  2  0  0 29 33\n",
      "  17 17 26  1 17 24 21 38 13 14 17 32 20 10  0 27  6  1 58 46 53 59  1 42\n",
      "  47 42 57 58  1 54 56 53 54 46 43 57 63  1 58 46 43  1 58 47 51 43  1 61\n",
      "  53 59 50 42]\n",
      " [58 53  1 41 53 51 43 11  1 44 53 56  1 58 46 39 58  1 58 46 53 59  1 46\n",
      "  39 57 58  0 25 47 57 59 57 43 42  1 43 56 43  1 59 57 43 42  6  1 40 63\n",
      "   1 58 47 51 43  1 51 47 57 59 57 43 42  1 53  5 43 56 54 39 57 58  8  0\n",
      "   0 23 21 26 19  1 30 21 15 20 13 30 16  1 21 21 21 10  0 13 57  1 21  1\n",
      "  47 52 58 43]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[63  6  0 32 46 39 58  1 21  1 51 39 63  1 50 47 60 43  1 58 53  1 57 39\n",
      "  63  6  1 32 46 43  1 42 53 45  1 47 57  1 42 43 39 42  2  0  0 29 33 17\n",
      "  17 26  1 17 24 21 38 13 14 17 32 20 10  0 27  6  1 58 46 53 59  1 42 47\n",
      "  42 57 58  1 54 56 53 54 46 43 57 63  1 58 46 43  1 58 47 51 43  1 61 53\n",
      "  59 50 42  1]\n",
      " [53  1 41 53 51 43 11  1 44 53 56  1 58 46 39 58  1 58 46 53 59  1 46 39\n",
      "  57 58  0 25 47 57 59 57 43 42  1 43 56 43  1 59 57 43 42  6  1 40 63  1\n",
      "  58 47 51 43  1 51 47 57 59 57 43 42  1 53  5 43 56 54 39 57 58  8  0  0\n",
      "  23 21 26 19  1 30 21 15 20 13 30 16  1 21 21 21 10  0 13 57  1 21  1 47\n",
      "  52 58 43 52]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[43  1 46 43 39 56 42  1 47 58  0 57 39 47 42  6  1 58 46 43  1 44 47 58\n",
      "  58 43 57 58  1 58 47 51 43  1 58 53  1 41 53 56 56 59 54 58  1 39  1 51\n",
      "  39 52  5 57  1 61 47 44 43  1 47 57  0 61 46 43 52  1 57 46 43  5 57  1\n",
      "  44 39 50 50 43 52  1 53 59 58  1 61 47 58 46  1 46 43 56  1 46 59 57 40\n",
      "  39 52 42  8]\n",
      " [43 39 58  1 14 53 50 47 52 45 40 56 53 49 43  6  0 25 53 59 52 58 43 42\n",
      "   1 59 54 53 52  1 39  1 46 53 58  1 39 52 42  1 44 47 43 56 63  1 57 58\n",
      "  43 43 42  0 35 46 47 41 46  1 46 47 57  1 39 57 54 47 56 47 52 45  1 56\n",
      "  47 42 43 56  1 57 43 43 51  5 42  1 58 53  1 49 52 53 61  6  0 35 47 58\n",
      "  46  1 57 50]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[ 1 46 43 39 56 42  1 47 58  0 57 39 47 42  6  1 58 46 43  1 44 47 58 58\n",
      "  43 57 58  1 58 47 51 43  1 58 53  1 41 53 56 56 59 54 58  1 39  1 51 39\n",
      "  52  5 57  1 61 47 44 43  1 47 57  0 61 46 43 52  1 57 46 43  5 57  1 44\n",
      "  39 50 50 43 52  1 53 59 58  1 61 47 58 46  1 46 43 56  1 46 59 57 40 39\n",
      "  52 42  8  1]\n",
      " [39 58  1 14 53 50 47 52 45 40 56 53 49 43  6  0 25 53 59 52 58 43 42  1\n",
      "  59 54 53 52  1 39  1 46 53 58  1 39 52 42  1 44 47 43 56 63  1 57 58 43\n",
      "  43 42  0 35 46 47 41 46  1 46 47 57  1 39 57 54 47 56 47 52 45  1 56 47\n",
      "  42 43 56  1 57 43 43 51  5 42  1 58 53  1 49 52 53 61  6  0 35 47 58 46\n",
      "   1 57 50 53]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[50 50 59 57  1 13 59 44 47 42 47 59 57  6  0 32 46 43  1 57 43 41 53 52\n",
      "  42  1 52 39 51 43  1 53 44  1 51 43 52  6  1 53 40 43 63 57  1 46 47 57\n",
      "   1 54 53 47 52 58 57  0 13 57  1 47 44  1 46 43  1 61 43 56 43  1 46 47\n",
      "  57  1 53 44 44 47 41 43 56 10  1 42 43 57 54 43 56 39 58 47 53 52  0 21\n",
      "  57  1 39 50]\n",
      " [40 59 58 58 53 52  6  1 39  1 42 59 43 50 50 47 57 58  6  1 39  1 42 59\n",
      "  43 50 50 47 57 58 11  1 39  1 45 43 52 58 50 43 51 39 52  1 53 44  1 58\n",
      "  46 43  0 60 43 56 63  1 44 47 56 57 58  1 46 53 59 57 43  6  1 53 44  1\n",
      "  58 46 43  1 44 47 56 57 58  1 39 52 42  1 57 43 41 53 52 42  1 41 39 59\n",
      "  57 43 10  0]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[50 59 57  1 13 59 44 47 42 47 59 57  6  0 32 46 43  1 57 43 41 53 52 42\n",
      "   1 52 39 51 43  1 53 44  1 51 43 52  6  1 53 40 43 63 57  1 46 47 57  1\n",
      "  54 53 47 52 58 57  0 13 57  1 47 44  1 46 43  1 61 43 56 43  1 46 47 57\n",
      "   1 53 44 44 47 41 43 56 10  1 42 43 57 54 43 56 39 58 47 53 52  0 21 57\n",
      "   1 39 50 50]\n",
      " [59 58 58 53 52  6  1 39  1 42 59 43 50 50 47 57 58  6  1 39  1 42 59 43\n",
      "  50 50 47 57 58 11  1 39  1 45 43 52 58 50 43 51 39 52  1 53 44  1 58 46\n",
      "  43  0 60 43 56 63  1 44 47 56 57 58  1 46 53 59 57 43  6  1 53 44  1 58\n",
      "  46 43  1 44 47 56 57 58  1 39 52 42  1 57 43 41 53 52 42  1 41 39 59 57\n",
      "  43 10  0 39]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[ 1 55 59 47 43 58 50 63  1 43 52 48 53 63  1 63 53 59 56  1 46 53 54 43\n",
      "   6  0 13 52 42  1 51 39 56 56 63  1 57 61 43 43 58  1 14 47 39 52 41 39\n",
      "   1 61 47 58 46  1 41 53 52 57 43 52 58  8  0  0 24 33 15 17 26 32 21 27\n",
      "  10  0 35 43 56 43  1 47 58  1 52 53 58  1 58 46 39 58  1 51 63  1 44 43\n",
      "  50 50 53 61]\n",
      " [47 39 52 39  5 57  1 57 39 49 43 10  1 40 59 58  1 39 57  1 46 43  1 39\n",
      "  42 48 59 42 45 43 42  1 63 53 59 56  1 40 56 53 58 46 43 56  6  7  7  0\n",
      "  14 43 47 52 45  1 41 56 47 51 47 52 39 50  6  1 47 52  1 42 53 59 40 50\n",
      "  43  1 60 47 53 50 39 58 47 53 52  0 27 44  1 57 39 41 56 43 42  1 41 46\n",
      "  39 57 58 47]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[55 59 47 43 58 50 63  1 43 52 48 53 63  1 63 53 59 56  1 46 53 54 43  6\n",
      "   0 13 52 42  1 51 39 56 56 63  1 57 61 43 43 58  1 14 47 39 52 41 39  1\n",
      "  61 47 58 46  1 41 53 52 57 43 52 58  8  0  0 24 33 15 17 26 32 21 27 10\n",
      "   0 35 43 56 43  1 47 58  1 52 53 58  1 58 46 39 58  1 51 63  1 44 43 50\n",
      "  50 53 61  7]\n",
      " [39 52 39  5 57  1 57 39 49 43 10  1 40 59 58  1 39 57  1 46 43  1 39 42\n",
      "  48 59 42 45 43 42  1 63 53 59 56  1 40 56 53 58 46 43 56  6  7  7  0 14\n",
      "  43 47 52 45  1 41 56 47 51 47 52 39 50  6  1 47 52  1 42 53 59 40 50 43\n",
      "   1 60 47 53 50 39 58 47 53 52  0 27 44  1 57 39 41 56 43 42  1 41 46 39\n",
      "  57 58 47 58]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[44 39 41 43  1 58 46 39 58  1 44 39 41 43 42  1 57 53  1 51 39 52 63  1\n",
      "  44 53 50 50 47 43 57  6  0 13 52 42  1 61 39 57  1 39 58  1 50 39 57 58\n",
      "   1 53 59 58  7 44 39 41 43 42  1 40 63  1 14 53 50 47 52 45 40 56 53 49\n",
      "  43 12  0 13  1 40 56 47 58 58 50 43  1 45 50 53 56 63  1 57 46 47 52 43\n",
      "  58 46  1 47]\n",
      " [57 50 39 47 52  8  0 13 52 42  6  1 39 57  1 46 43  1 44 43 50 50  6  1\n",
      "  42 47 42  1 30 53 51 43 53  1 58 59 56 52  1 39 52 42  1 44 50 63  8  0\n",
      "  32 46 47 57  1 47 57  1 58 46 43  1 58 56 59 58 46  6  1 53 56  1 50 43\n",
      "  58  1 14 43 52 60 53 50 47 53  1 42 47 43  8  0  0 24 13 16 37  1 15 13\n",
      "  28 33 24 17]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[39 41 43  1 58 46 39 58  1 44 39 41 43 42  1 57 53  1 51 39 52 63  1 44\n",
      "  53 50 50 47 43 57  6  0 13 52 42  1 61 39 57  1 39 58  1 50 39 57 58  1\n",
      "  53 59 58  7 44 39 41 43 42  1 40 63  1 14 53 50 47 52 45 40 56 53 49 43\n",
      "  12  0 13  1 40 56 47 58 58 50 43  1 45 50 53 56 63  1 57 46 47 52 43 58\n",
      "  46  1 47 52]\n",
      " [50 39 47 52  8  0 13 52 42  6  1 39 57  1 46 43  1 44 43 50 50  6  1 42\n",
      "  47 42  1 30 53 51 43 53  1 58 59 56 52  1 39 52 42  1 44 50 63  8  0 32\n",
      "  46 47 57  1 47 57  1 58 46 43  1 58 56 59 58 46  6  1 53 56  1 50 43 58\n",
      "   1 14 43 52 60 53 50 47 53  1 42 47 43  8  0  0 24 13 16 37  1 15 13 28\n",
      "  33 24 17 32]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[24 27 10  0 21  1 46 39 60 43  1 57 43 43 52  1 58 46 43 51  1 47 52  1\n",
      "  58 46 43  1 41 46 59 56 41 46  1 58 53 45 43 58 46 43 56 10  1 19 53 42\n",
      "   1 57 43 52 42  0  5 43 51  1 45 53 53 42  1 57 46 47 54 54 47 52 45  2\n",
      "   1 14 59 58  1 61 46 53  1 47 57  1 46 43 56 43 12  1 51 47 52 43  1 53\n",
      "  50 42  0 51]\n",
      " [52  8  0  0 13 30 15 20 21 16 13 25 33 31 10  0 35 53 59 50 42  1 58 46\n",
      "  43 63  1 43 50 57 43  1 40 43  1 41 53 52 58 43 52 58  1 58 53  1 42 47\n",
      "  43 12  0  0 15 13 25 21 24 24 27 10  0 37 43 57 11  1 47 44  1 58 46 43\n",
      "  56 43  1 61 43 56 43  1 52 53  1 53 58 46 43 56  1 43 62 41 59 57 43  1\n",
      "  61 46 63  1]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[27 10  0 21  1 46 39 60 43  1 57 43 43 52  1 58 46 43 51  1 47 52  1 58\n",
      "  46 43  1 41 46 59 56 41 46  1 58 53 45 43 58 46 43 56 10  1 19 53 42  1\n",
      "  57 43 52 42  0  5 43 51  1 45 53 53 42  1 57 46 47 54 54 47 52 45  2  1\n",
      "  14 59 58  1 61 46 53  1 47 57  1 46 43 56 43 12  1 51 47 52 43  1 53 50\n",
      "  42  0 51 39]\n",
      " [ 8  0  0 13 30 15 20 21 16 13 25 33 31 10  0 35 53 59 50 42  1 58 46 43\n",
      "  63  1 43 50 57 43  1 40 43  1 41 53 52 58 43 52 58  1 58 53  1 42 47 43\n",
      "  12  0  0 15 13 25 21 24 24 27 10  0 37 43 57 11  1 47 44  1 58 46 43 56\n",
      "  43  1 61 43 56 43  1 52 53  1 53 58 46 43 56  1 43 62 41 59 57 43  1 61\n",
      "  46 63  1 58]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[58  1 46 43 56  1 47 52  1 58 46 43  1 44 47 43 50 42  8  0  0 37 27 30\n",
      "  23 10  0 35 46 39 58  6  1 61 47 58 46  1 44 47 60 43  1 58 46 53 59 57\n",
      "  39 52 42  1 51 43 52 12  0  0 30 21 15 20 13 30 16 10  0 13 63  6  1 61\n",
      "  47 58 46  1 44 47 60 43  1 46 59 52 42 56 43 42  6  1 44 39 58 46 43 56\n",
      "   6  1 44 53]\n",
      " [46 43  1 18 47 44 58 46  6  0 35 46 53  1 51 39 42 43  1 58 46 43  1 16\n",
      "  39 59 54 46 47 52  1 39 52 42  1 58 46 43  1 18 56 43 52 41 46  1 58 53\n",
      "   1 57 58 53 53 54  0 13 52 42  1 57 43 47 64 43 42  1 59 54 53 52  1 58\n",
      "  46 43 47 56  1 58 53 61 52 57  1 39 52 42  1 54 56 53 60 47 52 41 43 57\n",
      "   8  0  0 35]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[ 1 46 43 56  1 47 52  1 58 46 43  1 44 47 43 50 42  8  0  0 37 27 30 23\n",
      "  10  0 35 46 39 58  6  1 61 47 58 46  1 44 47 60 43  1 58 46 53 59 57 39\n",
      "  52 42  1 51 43 52 12  0  0 30 21 15 20 13 30 16 10  0 13 63  6  1 61 47\n",
      "  58 46  1 44 47 60 43  1 46 59 52 42 56 43 42  6  1 44 39 58 46 43 56  6\n",
      "   1 44 53 56]\n",
      " [43  1 18 47 44 58 46  6  0 35 46 53  1 51 39 42 43  1 58 46 43  1 16 39\n",
      "  59 54 46 47 52  1 39 52 42  1 58 46 43  1 18 56 43 52 41 46  1 58 53  1\n",
      "  57 58 53 53 54  0 13 52 42  1 57 43 47 64 43 42  1 59 54 53 52  1 58 46\n",
      "  43 47 56  1 58 53 61 52 57  1 39 52 42  1 54 56 53 60 47 52 41 43 57  8\n",
      "   0  0 35 13]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[57 61 43 56  8  0  0 24 17 27 26 32 17 31 10  0 27  1 28 39 59 50 47 52\n",
      "  39  6  0 35 43  1 46 53 52 53 59 56  1 63 53 59  1 61 47 58 46  1 58 56\n",
      "  53 59 40 50 43 10  1 40 59 58  1 61 43  1 41 39 51 43  0 32 53  1 57 43\n",
      "  43  1 58 46 43  1 57 58 39 58 59 43  1 53 44  1 53 59 56  1 55 59 43 43\n",
      "  52 10  1 63]\n",
      " [42 11  1 44 39 47 58 46  6  1 37 53 59  5 50 50  1 40 43  1 57 47 41 49\n",
      "   1 58 53  7 51 53 56 56 53 61  0 18 53 56  1 58 46 47 57  1 52 47 45 46\n",
      "  58  5 57  1 61 39 58 41 46 47 52 45  8  0  0 15 13 28 33 24 17 32 10  0\n",
      "  26 53  6  1 52 53 58  1 39  1 61 46 47 58 10  1 61 46 39 58  2  1 21  1\n",
      "  46 39 60 43]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[61 43 56  8  0  0 24 17 27 26 32 17 31 10  0 27  1 28 39 59 50 47 52 39\n",
      "   6  0 35 43  1 46 53 52 53 59 56  1 63 53 59  1 61 47 58 46  1 58 56 53\n",
      "  59 40 50 43 10  1 40 59 58  1 61 43  1 41 39 51 43  0 32 53  1 57 43 43\n",
      "   1 58 46 43  1 57 58 39 58 59 43  1 53 44  1 53 59 56  1 55 59 43 43 52\n",
      "  10  1 63 53]\n",
      " [11  1 44 39 47 58 46  6  1 37 53 59  5 50 50  1 40 43  1 57 47 41 49  1\n",
      "  58 53  7 51 53 56 56 53 61  0 18 53 56  1 58 46 47 57  1 52 47 45 46 58\n",
      "   5 57  1 61 39 58 41 46 47 52 45  8  0  0 15 13 28 33 24 17 32 10  0 26\n",
      "  53  6  1 52 53 58  1 39  1 61 46 47 58 10  1 61 46 39 58  2  1 21  1 46\n",
      "  39 60 43  1]], shape=(2, 100), dtype=int64)\n",
      "Input data:  tf.Tensor(\n",
      "[[51 57  1 39 54 54 50 47 43 42  1 58 53  6  1 63 53 59  6  1 63 43 58  1\n",
      "  42 39 56 43  1 21  1 52 43 60 43 56  0 16 43 52 63  1 63 53 59 56  1 39\n",
      "  57 49 47 52 45 10  1 58 39 49 43  1 63 53 59 56  1 41 46 53 47 41 43  1\n",
      "  53 44  1 58 46 53 57 43  0 32 46 39 58  1 40 43 57 58  1 41 39 52  1 39\n",
      "  47 42  1 63]\n",
      " [43  1 39 58 58 43 52 58 47 53 52  1 50 47 49 43  1 42 43 43 54  1 46 39\n",
      "  56 51 53 52 63 10  0 35 46 43 56 43  1 61 53 56 42 57  1 39 56 43  1 57\n",
      "  41 39 56 41 43  6  1 58 46 43 63  1 39 56 43  1 57 43 50 42 53 51  1 57\n",
      "  54 43 52 58  1 47 52  1 60 39 47 52  6  0 18 53 56  1 58 46 43 63  1 40\n",
      "  56 43 39 58]], shape=(2, 100), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[57  1 39 54 54 50 47 43 42  1 58 53  6  1 63 53 59  6  1 63 43 58  1 42\n",
      "  39 56 43  1 21  1 52 43 60 43 56  0 16 43 52 63  1 63 53 59 56  1 39 57\n",
      "  49 47 52 45 10  1 58 39 49 43  1 63 53 59 56  1 41 46 53 47 41 43  1 53\n",
      "  44  1 58 46 53 57 43  0 32 46 39 58  1 40 43 57 58  1 41 39 52  1 39 47\n",
      "  42  1 63 53]\n",
      " [ 1 39 58 58 43 52 58 47 53 52  1 50 47 49 43  1 42 43 43 54  1 46 39 56\n",
      "  51 53 52 63 10  0 35 46 43 56 43  1 61 53 56 42 57  1 39 56 43  1 57 41\n",
      "  39 56 41 43  6  1 58 46 43 63  1 39 56 43  1 57 43 50 42 53 51  1 57 54\n",
      "  43 52 58  1 47 52  1 60 39 47 52  6  0 18 53 56  1 58 46 43 63  1 40 56\n",
      "  43 39 58 46]], shape=(2, 100), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(23):\n",
    "  print ('Input data: ', input_example[:2])\n",
    "  print ('Target data:', target_example[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "  rnn = tf.keras.layers.CuDNNGRU\n",
    "else:\n",
    "  rnn = functools.partial(\n",
    "  tf.keras.layers.GRU, recurrent_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    rnn(rnn_units,\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab), \n",
    "  embedding_dim=embedding_dim, \n",
    "  rnn_units=rnn_units, \n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1): \n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3935232   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 4,018,497\n",
      "Trainable params: 4,018,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.1754208\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "174/174 [==============================] - 927s 5s/step - loss: 2.6346\n",
      "Epoch 2/3\n",
      "174/174 [==============================] - 937s 5s/step - loss: 1.9306\n",
      "Epoch 3/3\n",
      "174/174 [==============================] - 940s 5s/step - loss: 1.6742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f20c376cb00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset.repeat(), epochs=3, steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing) \n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a multinomial distribution to predict the word returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "      \n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (1, None, 1024)           3935232   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 4,018,497\n",
      "Trainable params: 4,018,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_predict.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-41-fa9dfcbd0edf>:28: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "ROMEO: Three of tercust for children;\n",
      "My As I soul face, and delivered, hither,\n",
      "Led his lubite?\n",
      "Undain honour Marracia; I amsul words after-coment'd ade\n",
      "will have year hear'd part I sir,\n",
      "Come in which on't with full'd uname.\n",
      "A quarbell and be ole but not much forour'd\n",
      "Take house? makth if a grant his?\n",
      "Thing is un you and grace, and but\n",
      "She sight-call for mark bothed both hime;\n",
      "Here's not the life of it,\n",
      "Wo bess begeing totlied, by no matth, knowness\n",
      "When saint MeF us you hath a fleeth.\n",
      "\n",
      "BAPTIATA:\n",
      "I; divinest:\n",
      "Mony Clarented up dlish inctlower you see sur ends,\n",
      "Was we my thint whe and Working suchrem-not\n",
      "The English a cruld: me foo worand us don!\n",
      "And Mantague to Gover he brot:\n",
      "The lest me, bid then tow the vime,-woold with Grouse:\n",
      "How ohe his paitos's of athe take the power and or apladion\n",
      "Towered for these crewncus of the ill-abus flow the sharout!\n",
      "All they kell of rocome lord, and 'in word?\n",
      "He contlenatcy pursouls, in that tase you a dadghen!\n",
      "I have I take commstiven as I shall for-RGET:\n",
      "Thi\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_predict, start_string=u\"ROMEO: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.4672\n",
      "Epoch 1 Batch 100 Loss 1.4520\n",
      "Epoch 1 Loss 1.4202\n",
      "Time taken for 1 epoch 1209.668173789978 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "# Training step\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    # initializing the hidden state at the start of every epoch\n",
    "    # initally hidden is None\n",
    "    hidden = model.reset_states()\n",
    "    \n",
    "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "          with tf.GradientTape() as tape:\n",
    "              # feeding the hidden state back into the model\n",
    "              # This is the interesting step\n",
    "              predictions = model(inp)\n",
    "              loss = tf.losses.sparse_softmax_cross_entropy(target, predictions)\n",
    "              \n",
    "          grads = tape.gradient(loss, model.trainable_variables)\n",
    "          optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "          if batch_n % 100 == 0:\n",
    "              template = 'Epoch {} Batch {} Loss {:.4f}'\n",
    "              print(template.format(epoch+1, batch_n, loss))\n",
    "\n",
    "    # saving (checkpoint) the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "      model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/data/spa-eng.zip\n",
      "2646016/2638744 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://download.tensorflow.org/data/spa-eng.zip', \n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    \n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", w)\n",
    "    \n",
    "    w = w.rstrip().strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    \n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "    \n",
    "    return word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
    "# (e.g., 5 -> \"dad\") for each language,\n",
    "class LanguageIndex():\n",
    "  def __init__(self, lang):\n",
    "    self.lang = lang\n",
    "    self.word2idx = {}\n",
    "    self.idx2word = {}\n",
    "    self.vocab = set()\n",
    "    \n",
    "    self.create_index()\n",
    "    \n",
    "  def create_index(self):\n",
    "    for phrase in self.lang:\n",
    "      self.vocab.update(phrase.split(' '))\n",
    "    \n",
    "    self.vocab = sorted(self.vocab)\n",
    "    \n",
    "    self.word2idx['<pad>'] = 0\n",
    "    for index, word in enumerate(self.vocab):\n",
    "      self.word2idx[word] = index + 1\n",
    "    \n",
    "    for word, index in self.word2idx.items():\n",
    "      self.idx2word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "\n",
    "def load_dataset(path, num_examples):\n",
    "    # creating cleaned input, output pairs\n",
    "    pairs = create_dataset(path, num_examples)\n",
    "\n",
    "    # index language using the class defined above    \n",
    "    inp_lang = LanguageIndex(sp for en, sp in pairs)\n",
    "    targ_lang = LanguageIndex(en for en, sp in pairs)\n",
    "    \n",
    "    # Vectorize the input and target languages\n",
    "    \n",
    "    # Spanish sentences\n",
    "    input_tensor = [[inp_lang.word2idx[s] for s in sp.split(' ')] for en, sp in pairs]\n",
    "    \n",
    "    # English sentences\n",
    "    target_tensor = [[targ_lang.word2idx[s] for s in en.split(' ')] for en, sp in pairs]\n",
    "    \n",
    "    # Calculate max_length of input and output tensor\n",
    "    # Here, we'll set those to the longest sentence in the dataset\n",
    "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
    "    \n",
    "    # Padding the input and output tensor to the maximum length\n",
    "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
    "                                                                 maxlen=max_length_inp,\n",
    "                                                                 padding='post')\n",
    "    \n",
    "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
    "                                                                  maxlen=max_length_tar, \n",
    "                                                                  padding='post')\n",
    "    \n",
    "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(path_to_file, num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 24000, 6000, 6000)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
    "  # the code automatically does that.\n",
    "  if tf.test.is_gpu_available():\n",
    "    return tf.keras.layers.CuDNNGRU(units, \n",
    "                                    return_sequences=True, \n",
    "                                    return_state=True, \n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "  else:\n",
    "    return tf.keras.layers.GRU(units, \n",
    "                               return_sequences=True, \n",
    "                               return_state=True, \n",
    "                               recurrent_activation='sigmoid', \n",
    "                               recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)        \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = 1 - np.equal(real, 0)\n",
    "  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.6143\n",
      "Epoch 1 Batch 100 Loss 2.2430\n",
      "Epoch 1 Batch 200 Loss 1.8499\n",
      "Epoch 1 Batch 300 Loss 1.7281\n",
      "Epoch 1 Loss 2.0630\n",
      "Time taken for 1 epoch 1482.4521238803864 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.6600\n",
      "Epoch 2 Batch 100 Loss 1.5209\n",
      "Epoch 2 Batch 200 Loss 1.4711\n",
      "Epoch 2 Batch 300 Loss 1.4244\n",
      "Epoch 2 Loss 1.4583\n",
      "Time taken for 1 epoch 1483.3327887058258 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.1754\n",
      "Epoch 3 Batch 100 Loss 1.1892\n",
      "Epoch 3 Batch 200 Loss 1.1323\n",
      "Epoch 3 Batch 300 Loss 1.1086\n",
      "Epoch 3 Loss 1.0850\n",
      "Time taken for 1 epoch 1499.8889770507812 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.7878\n",
      "Epoch 4 Batch 100 Loss 0.7402\n",
      "Epoch 4 Batch 200 Loss 0.6231\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-5146a4bf6d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1130\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5307\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5308\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5309\u001b[0;31m         \"transpose_b\", transpose_b)\n\u001b[0m\u001b[1;32m   5310\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5311\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(inp, hidden)\n",
    "            \n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)       \n",
    "            \n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(1, targ.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                loss += loss_function(targ[:, t], predictions)\n",
    "                \n",
    "                # using teacher forcing\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "        \n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / N_BATCH))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.idx2word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.idx2word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
    "        \n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "translate(u'hace mucho frio aqui.', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'todavia estan en casa?', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong translation\n",
    "translate(u'trata de averiguarlo.', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
